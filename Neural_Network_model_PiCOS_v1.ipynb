{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Necessary Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "TRyR6kiFDWTY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F6dfUl-fa1NM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid', color_codes=True)\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data"
      ],
      "metadata": {
        "id": "gc1GL5-HDiVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the cleaned dataset"
      ],
      "metadata": {
        "id": "EhWvtRDiDqJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel(\"/content/PiCOS_cleaned_data_engineered.xlsx\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "4gjoHpn4dvoR",
        "outputId": "0048fe6e-db83-4047-8b16-695c1df5b6e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PCOS (Y/N)        BMI  Blood Group  Cycle(R/I)  Marraige Status (Yrs)  \\\n",
              "0           0  19.300000           15           2                    7.0   \n",
              "1           0  24.921163           15           2                   11.0   \n",
              "2           1  25.270891           11           2                   10.0   \n",
              "3           0  29.674945           13           2                    4.0   \n",
              "4           0  20.060954           11           2                    1.0   \n",
              "\n",
              "   Pregnant(Y/N)  No. of aborptions  Waist:Hip Ratio  Weight gain(Y/N)  \\\n",
              "0              0                  0         0.833333                 0   \n",
              "1              1                  0         0.842105                 0   \n",
              "2              1                  0         0.900000                 0   \n",
              "3              0                  0         0.857143                 0   \n",
              "4              1                  0         0.810811                 0   \n",
              "\n",
              "   hair growth(Y/N)  Skin darkening (Y/N)  Hair loss(Y/N)  Pimples(Y/N)  \\\n",
              "0                 0                     0               0             0   \n",
              "1                 0                     0               0             0   \n",
              "2                 0                     0               1             1   \n",
              "3                 0                     0               0             0   \n",
              "4                 0                     0               1             0   \n",
              "\n",
              "   Fast food (Y/N)  Reg.Exercise(Y/N)  age_category  marriage_category  \n",
              "0                1                  0             2                  2  \n",
              "1                0                  0             3                  3  \n",
              "2                1                  0             3                  2  \n",
              "3                0                  0             3                  1  \n",
              "4                0                  0             2                  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fec530b9-b499-47e1-90e0-6b278d233e73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PCOS (Y/N)</th>\n",
              "      <th>BMI</th>\n",
              "      <th>Blood Group</th>\n",
              "      <th>Cycle(R/I)</th>\n",
              "      <th>Marraige Status (Yrs)</th>\n",
              "      <th>Pregnant(Y/N)</th>\n",
              "      <th>No. of aborptions</th>\n",
              "      <th>Waist:Hip Ratio</th>\n",
              "      <th>Weight gain(Y/N)</th>\n",
              "      <th>hair growth(Y/N)</th>\n",
              "      <th>Skin darkening (Y/N)</th>\n",
              "      <th>Hair loss(Y/N)</th>\n",
              "      <th>Pimples(Y/N)</th>\n",
              "      <th>Fast food (Y/N)</th>\n",
              "      <th>Reg.Exercise(Y/N)</th>\n",
              "      <th>age_category</th>\n",
              "      <th>marriage_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>24.921163</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>25.270891</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>29.674945</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>20.060954</td>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fec530b9-b499-47e1-90e0-6b278d233e73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fec530b9-b499-47e1-90e0-6b278d233e73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fec530b9-b499-47e1-90e0-6b278d233e73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0BF6LQvu2eQ",
        "outputId": "94b226ae-7ce5-42cf-9181-912c3f58b4ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 534 entries, 0 to 533\n",
            "Data columns (total 17 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   PCOS (Y/N)             534 non-null    int64  \n",
            " 1   BMI                    534 non-null    float64\n",
            " 2   Blood Group            534 non-null    int64  \n",
            " 3   Cycle(R/I)             534 non-null    int64  \n",
            " 4   Marraige Status (Yrs)  534 non-null    float64\n",
            " 5   Pregnant(Y/N)          534 non-null    int64  \n",
            " 6   No. of aborptions      534 non-null    int64  \n",
            " 7   Waist:Hip Ratio        534 non-null    float64\n",
            " 8   Weight gain(Y/N)       534 non-null    int64  \n",
            " 9   hair growth(Y/N)       534 non-null    int64  \n",
            " 10  Skin darkening (Y/N)   534 non-null    int64  \n",
            " 11  Hair loss(Y/N)         534 non-null    int64  \n",
            " 12  Pimples(Y/N)           534 non-null    int64  \n",
            " 13  Fast food (Y/N)        534 non-null    int64  \n",
            " 14  Reg.Exercise(Y/N)      534 non-null    int64  \n",
            " 15  age_category           534 non-null    int64  \n",
            " 16  marriage_category      534 non-null    int64  \n",
            "dtypes: float64(3), int64(14)\n",
            "memory usage: 71.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the cleaned dataset and perform any required preprocessing steps, since the data has been cleaned neatly by dropping the unnecessary columns and removing any nulls, we can proceed to the next step\n",
        "\n",
        "We label the data to fit the neural networks. The X should contains PCOS symptoms so we drop the targeted label (y) and set the axis to 1 (this is to make sure it drops the columns\n",
        "\n",
        "Then, we set the targeted label (y) to whether someone is diagnosed with PCOS or not"
      ],
      "metadata": {
        "id": "F5Yhw51xDwWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X  = df.drop(['PCOS (Y/N)', 'Marraige Status (Yrs)'], axis = 1)\n",
        "y = df[[\"PCOS (Y/N)\"]]"
      ],
      "metadata": {
        "id": "rAjTrKmYd6aO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpJh0lFYfBbD",
        "outputId": "e2be6340-5ab9-4583-a936-5cacdabd5d0c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 534 entries, 0 to 533\n",
            "Data columns (total 15 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   BMI                   534 non-null    float64\n",
            " 1   Blood Group           534 non-null    int64  \n",
            " 2   Cycle(R/I)            534 non-null    int64  \n",
            " 3   Pregnant(Y/N)         534 non-null    int64  \n",
            " 4   No. of aborptions     534 non-null    int64  \n",
            " 5   Waist:Hip Ratio       534 non-null    float64\n",
            " 6   Weight gain(Y/N)      534 non-null    int64  \n",
            " 7   hair growth(Y/N)      534 non-null    int64  \n",
            " 8   Skin darkening (Y/N)  534 non-null    int64  \n",
            " 9   Hair loss(Y/N)        534 non-null    int64  \n",
            " 10  Pimples(Y/N)          534 non-null    int64  \n",
            " 11  Fast food (Y/N)       534 non-null    int64  \n",
            " 12  Reg.Exercise(Y/N)     534 non-null    int64  \n",
            " 13  age_category          534 non-null    int64  \n",
            " 14  marriage_category     534 non-null    int64  \n",
            "dtypes: float64(2), int64(13)\n",
            "memory usage: 62.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQUuNUT-fCWj",
        "outputId": "47a629d6-ae59-4579-b2f8-099fdb560afc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 534 entries, 0 to 533\n",
            "Data columns (total 1 columns):\n",
            " #   Column      Non-Null Count  Dtype\n",
            "---  ------      --------------  -----\n",
            " 0   PCOS (Y/N)  534 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 4.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split the Dataset\n",
        "After labeling the data to X and y, the next step is to split the data into several set, this is to make sure that the data used for training isn't used for developing and testing. This step helps model avoids overfitting."
      ],
      "metadata": {
        "id": "ZEKEj13pEmOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0, stratify= y)"
      ],
      "metadata": {
        "id": "2dDU1HxUf_py"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2, random_state=0, stratify= y_train)\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wb5guzB4gw9-",
        "outputId": "15e14fcd-d2e0-4b6c-a2a3-297166bcce8e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(384, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8qKfTS3hYgp",
        "outputId": "254aa8ae-fb4f-4dc2-b611-40ccbcdfb770"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_dev.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYWo8ArNheS0",
        "outputId": "98b89466-6684-41ec-c13a-51d8875172ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GHNGY3R992P",
        "outputId": "5227c4d4-0c32-4e74-8761-405d9c435b92"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(384, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GVyR36U_FUu",
        "outputId": "923d48cb-7749-4b95-8e17-67e22de96754"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(384, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_test).info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFFm79hBAKeP",
        "outputId": "1fbfe5e8-7593-4023-b1d3-6d25f1430ef7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 54 entries, 214 to 358\n",
            "Data columns (total 1 columns):\n",
            " #   Column      Non-Null Count  Dtype\n",
            "---  ------      --------------  -----\n",
            " 0   PCOS (Y/N)  54 non-null     int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 864.0 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "print(rf.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA_Gn3FFPIBG",
        "outputId": "8ced66f9-f329-4ab0-e803-629aa11ca84e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-f4d8d14cacb8>:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(X_train, y_train)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "map_imp = {key:value for key, value in zip(X.columns, rf.feature_importances_)}\n",
        "pd.DataFrame({'col':X.columns, 'importance':rf.feature_importances_}).sort_values('importance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "2KYkJ9hIP2hg",
        "outputId": "1722385d-4117-415a-bc6c-c6f956c3b09e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     col  importance\n",
              "4      No. of aborptions    0.019081\n",
              "3          Pregnant(Y/N)    0.021712\n",
              "9         Hair loss(Y/N)    0.026609\n",
              "12     Reg.Exercise(Y/N)    0.032263\n",
              "10          Pimples(Y/N)    0.042561\n",
              "13          age_category    0.042727\n",
              "11       Fast food (Y/N)    0.046857\n",
              "1            Blood Group    0.047785\n",
              "14     marriage_category    0.047916\n",
              "2             Cycle(R/I)    0.091025\n",
              "7       hair growth(Y/N)    0.094523\n",
              "6       Weight gain(Y/N)    0.094919\n",
              "5        Waist:Hip Ratio    0.124050\n",
              "8   Skin darkening (Y/N)    0.130037\n",
              "0                    BMI    0.137935"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69655770-288a-4571-9fb8-d2fbb748a82f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>col</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No. of aborptions</td>\n",
              "      <td>0.019081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pregnant(Y/N)</td>\n",
              "      <td>0.021712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hair loss(Y/N)</td>\n",
              "      <td>0.026609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Reg.Exercise(Y/N)</td>\n",
              "      <td>0.032263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Pimples(Y/N)</td>\n",
              "      <td>0.042561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>age_category</td>\n",
              "      <td>0.042727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Fast food (Y/N)</td>\n",
              "      <td>0.046857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Blood Group</td>\n",
              "      <td>0.047785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>marriage_category</td>\n",
              "      <td>0.047916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cycle(R/I)</td>\n",
              "      <td>0.091025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hair growth(Y/N)</td>\n",
              "      <td>0.094523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Weight gain(Y/N)</td>\n",
              "      <td>0.094919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Waist:Hip Ratio</td>\n",
              "      <td>0.124050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Skin darkening (Y/N)</td>\n",
              "      <td>0.130037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BMI</td>\n",
              "      <td>0.137935</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69655770-288a-4571-9fb8-d2fbb748a82f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69655770-288a-4571-9fb8-d2fbb748a82f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69655770-288a-4571-9fb8-d2fbb748a82f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scale the Features\n",
        "The next step of building model is to scale the features to make sure all of the features is calculated evenly. Here, we use Minmax scaling because the data we have are mostly structured data (0 or 1). So, we tried to make all the features in our data ranging from 0 to 1"
      ],
      "metadata": {
        "id": "oBac9bDFkJVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler().fit(X_train)\n",
        "\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "\n",
        "X_dev = scaler.transform(X_dev)\n",
        "X_dev = pd.DataFrame(X_dev)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "X_test = pd.DataFrame(X_test)"
      ],
      "metadata": {
        "id": "YxRHk_pkhhQm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to apply random noise to data\n",
        "def add_random_noise(data, noise_level):\n",
        "    noise = np.random.normal(0, noise_level, size=data.shape)\n",
        "    augmented_data = data + noise\n",
        "    return augmented_data\n",
        "\n",
        "# Function to apply random scaling to data\n",
        "def apply_random_scaling(data, scaling_range):\n",
        "    scaling_factor = np.random.uniform(*scaling_range)\n",
        "    augmented_data = data * scaling_factor\n",
        "    return augmented_data\n",
        "\n",
        "# Function to apply random shifting to data\n",
        "def apply_random_shift(data, shift_range):\n",
        "    shift_offset = np.random.uniform(*shift_range)\n",
        "    augmented_data = data + shift_offset\n",
        "    return augmented_data"
      ],
      "metadata": {
        "id": "D4C77A6MBkQF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if X_train is already a NumPy array\n",
        "if not isinstance(X_train, np.ndarray):\n",
        "    X_train = np.array(X_train)"
      ],
      "metadata": {
        "id": "SKU3TXJtFiUL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X_train and y_train are your initial training dataset and corresponding labels\n",
        "X_train_augmented = []\n",
        "y_train_augmented = []\n",
        "\n",
        "# Apply data augmentation to each sample in X_train\n",
        "for idx, sample in enumerate(X_train):\n",
        "    augmented_sample = add_random_noise(sample, noise_level=0.1)  # Apply your data augmentation function here\n",
        "    X_train_augmented.append(augmented_sample)\n",
        "\n",
        "# Convert the augmented data to numpy arrays\n",
        "X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = y_train.copy()\n",
        "\n",
        "# Concatenate the initial X_train with the augmented data\n",
        "X_train_combined = np.concatenate((X_train, X_train_augmented), axis=0)\n",
        "y_train_combined = np.concatenate((y_train, y_train_augmented), axis=0)"
      ],
      "metadata": {
        "id": "p481yPghC6UP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Create the Random Oversampler\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "\n",
        "# Apply the oversampling to your data\n",
        "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train_combined, y_train_combined)"
      ],
      "metadata": {
        "id": "qpA7ZNSjOpPO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming y_train is the label array\n",
        "num_zeros = np.count_nonzero(y_train_oversampled == 0)\n",
        "num_ones = np.count_nonzero(y_train_oversampled == 1)\n",
        "\n",
        "print(\"Number of 0s:\", num_zeros)\n",
        "print(\"Number of 1s:\", num_ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkvovftUPVtT",
        "outputId": "e569e443-845c-4480-9dad-f6772c66d240"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of 0s: 514\n",
            "Number of 1s: 514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X_train_oversampled).info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0FhRTVgEsbi",
        "outputId": "cbffde7a-b262-4ca6-bedb-3f931481cbe0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1028 entries, 0 to 1027\n",
            "Data columns (total 15 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       1028 non-null   float64\n",
            " 1   1       1028 non-null   float64\n",
            " 2   2       1028 non-null   float64\n",
            " 3   3       1028 non-null   float64\n",
            " 4   4       1028 non-null   float64\n",
            " 5   5       1028 non-null   float64\n",
            " 6   6       1028 non-null   float64\n",
            " 7   7       1028 non-null   float64\n",
            " 8   8       1028 non-null   float64\n",
            " 9   9       1028 non-null   float64\n",
            " 10  10      1028 non-null   float64\n",
            " 11  11      1028 non-null   float64\n",
            " 12  12      1028 non-null   float64\n",
            " 13  13      1028 non-null   float64\n",
            " 14  14      1028 non-null   float64\n",
            "dtypes: float64(15)\n",
            "memory usage: 120.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Model"
      ],
      "metadata": {
        "id": "8tWNqkbkk7t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout"
      ],
      "metadata": {
        "id": "qgOEqor29Ddq"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_np = X_train.to_numpy().reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "# X_test_np = X_test.to_numpy().reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "X_dev_np = X_dev.to_numpy().reshape(X_dev.shape[0], X_dev.shape[1], 1)"
      ],
      "metadata": {
        "id": "jNmndjl39EML"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of input features\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# Build the Sequential model\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Input(input_shape))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "learning_rate = 0.001\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model.build(X_train.shape[1:])\n"
      ],
      "metadata": {
        "id": "m3aHbkkcipfk"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "# y_train = to_categorical(y_train, 2)\n",
        "# y_test = to_categorical(y_test, 2)\n",
        "# y_dev = to_categorical(y_dev, 2)"
      ],
      "metadata": {
        "id": "IONBKUKQ9Qst"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVin4kPSrz7q",
        "outputId": "33a8b944-b198-47ed-8fba-4497b1b77b3b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 534 entries, 0 to 533\n",
            "Data columns (total 15 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   BMI                   534 non-null    float64\n",
            " 1   Blood Group           534 non-null    int64  \n",
            " 2   Cycle(R/I)            534 non-null    int64  \n",
            " 3   Pregnant(Y/N)         534 non-null    int64  \n",
            " 4   No. of aborptions     534 non-null    int64  \n",
            " 5   Waist:Hip Ratio       534 non-null    float64\n",
            " 6   Weight gain(Y/N)      534 non-null    int64  \n",
            " 7   hair growth(Y/N)      534 non-null    int64  \n",
            " 8   Skin darkening (Y/N)  534 non-null    int64  \n",
            " 9   Hair loss(Y/N)        534 non-null    int64  \n",
            " 10  Pimples(Y/N)          534 non-null    int64  \n",
            " 11  Fast food (Y/N)       534 non-null    int64  \n",
            " 12  Reg.Exercise(Y/N)     534 non-null    int64  \n",
            " 13  age_category          534 non-null    int64  \n",
            " 14  marriage_category     534 non-null    int64  \n",
            "dtypes: float64(2), int64(13)\n",
            "memory usage: 62.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEBLfrhbBpCL",
        "outputId": "77110629-3912-4ef8-a9bf-c84863d9c5c8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                1024      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 64)               256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,753\n",
            "Trainable params: 6,497\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rds5rRjLL5i6",
        "outputId": "21dd97d5-a645-4186-e205-c1a775185e6f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(384, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 250\n",
        "batch_size = 20\n",
        "\n",
        "model.fit(X_train_combined, y_train_combined, epochs=epochs, batch_size=batch_size, verbose=1, validation_data= (X_dev,y_dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvwBizw-kukm",
        "outputId": "e53bc4fe-8557-4f1a-f093-17cc4d3b81ca"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "39/39 [==============================] - 2s 9ms/step - loss: 0.7144 - accuracy: 0.6016 - val_loss: 0.6448 - val_accuracy: 0.7500\n",
            "Epoch 2/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.5638 - accuracy: 0.7148 - val_loss: 0.6097 - val_accuracy: 0.7083\n",
            "Epoch 3/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7682 - val_loss: 0.5789 - val_accuracy: 0.7292\n",
            "Epoch 4/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8008 - val_loss: 0.5531 - val_accuracy: 0.7604\n",
            "Epoch 5/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.8112 - val_loss: 0.5323 - val_accuracy: 0.7396\n",
            "Epoch 6/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.8047 - val_loss: 0.5166 - val_accuracy: 0.7604\n",
            "Epoch 7/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.8112 - val_loss: 0.5106 - val_accuracy: 0.7812\n",
            "Epoch 8/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8086 - val_loss: 0.4987 - val_accuracy: 0.8021\n",
            "Epoch 9/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8385 - val_loss: 0.4946 - val_accuracy: 0.8021\n",
            "Epoch 10/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3811 - accuracy: 0.8477 - val_loss: 0.4940 - val_accuracy: 0.8021\n",
            "Epoch 11/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.8359 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
            "Epoch 12/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8294 - val_loss: 0.5057 - val_accuracy: 0.7812\n",
            "Epoch 13/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8529 - val_loss: 0.5123 - val_accuracy: 0.7812\n",
            "Epoch 14/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8477 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
            "Epoch 15/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8451 - val_loss: 0.5175 - val_accuracy: 0.7500\n",
            "Epoch 16/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8555 - val_loss: 0.5171 - val_accuracy: 0.7812\n",
            "Epoch 17/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8581 - val_loss: 0.5269 - val_accuracy: 0.7812\n",
            "Epoch 18/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3864 - accuracy: 0.8359 - val_loss: 0.5329 - val_accuracy: 0.7708\n",
            "Epoch 19/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8581 - val_loss: 0.5233 - val_accuracy: 0.7708\n",
            "Epoch 20/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8594 - val_loss: 0.5418 - val_accuracy: 0.7708\n",
            "Epoch 21/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8503 - val_loss: 0.5373 - val_accuracy: 0.7708\n",
            "Epoch 22/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3885 - accuracy: 0.8477 - val_loss: 0.5434 - val_accuracy: 0.7708\n",
            "Epoch 23/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8594 - val_loss: 0.5440 - val_accuracy: 0.7708\n",
            "Epoch 24/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8568 - val_loss: 0.5543 - val_accuracy: 0.7708\n",
            "Epoch 25/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3504 - accuracy: 0.8620 - val_loss: 0.5567 - val_accuracy: 0.7708\n",
            "Epoch 26/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8581 - val_loss: 0.5654 - val_accuracy: 0.7604\n",
            "Epoch 27/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3593 - accuracy: 0.8646 - val_loss: 0.5641 - val_accuracy: 0.7604\n",
            "Epoch 28/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8607 - val_loss: 0.5630 - val_accuracy: 0.7708\n",
            "Epoch 29/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8698 - val_loss: 0.5675 - val_accuracy: 0.7604\n",
            "Epoch 30/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8542 - val_loss: 0.5609 - val_accuracy: 0.7500\n",
            "Epoch 31/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8789 - val_loss: 0.5748 - val_accuracy: 0.7604\n",
            "Epoch 32/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8789 - val_loss: 0.5764 - val_accuracy: 0.7708\n",
            "Epoch 33/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8685 - val_loss: 0.5717 - val_accuracy: 0.7500\n",
            "Epoch 34/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8607 - val_loss: 0.5921 - val_accuracy: 0.7500\n",
            "Epoch 35/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8594 - val_loss: 0.5787 - val_accuracy: 0.7396\n",
            "Epoch 36/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8659 - val_loss: 0.5848 - val_accuracy: 0.7396\n",
            "Epoch 37/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8646 - val_loss: 0.5872 - val_accuracy: 0.7396\n",
            "Epoch 38/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8659 - val_loss: 0.6036 - val_accuracy: 0.7292\n",
            "Epoch 39/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8698 - val_loss: 0.6064 - val_accuracy: 0.7396\n",
            "Epoch 40/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8503 - val_loss: 0.6087 - val_accuracy: 0.7292\n",
            "Epoch 41/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8724 - val_loss: 0.5898 - val_accuracy: 0.7500\n",
            "Epoch 42/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8711 - val_loss: 0.5987 - val_accuracy: 0.7604\n",
            "Epoch 43/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8737 - val_loss: 0.6090 - val_accuracy: 0.7396\n",
            "Epoch 44/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8737 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
            "Epoch 45/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8672 - val_loss: 0.6206 - val_accuracy: 0.7708\n",
            "Epoch 46/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2825 - accuracy: 0.8906 - val_loss: 0.6444 - val_accuracy: 0.7500\n",
            "Epoch 47/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.3082 - accuracy: 0.8685 - val_loss: 0.6216 - val_accuracy: 0.7500\n",
            "Epoch 48/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.8750 - val_loss: 0.6338 - val_accuracy: 0.7396\n",
            "Epoch 49/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8854 - val_loss: 0.6542 - val_accuracy: 0.7396\n",
            "Epoch 50/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3152 - accuracy: 0.8802 - val_loss: 0.6320 - val_accuracy: 0.7396\n",
            "Epoch 51/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8841 - val_loss: 0.6440 - val_accuracy: 0.7396\n",
            "Epoch 52/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2720 - accuracy: 0.8880 - val_loss: 0.6785 - val_accuracy: 0.7396\n",
            "Epoch 53/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2964 - accuracy: 0.8737 - val_loss: 0.6708 - val_accuracy: 0.7396\n",
            "Epoch 54/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.8750 - val_loss: 0.6990 - val_accuracy: 0.7292\n",
            "Epoch 55/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8789 - val_loss: 0.6369 - val_accuracy: 0.7812\n",
            "Epoch 56/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.8919 - val_loss: 0.6358 - val_accuracy: 0.7708\n",
            "Epoch 57/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8841 - val_loss: 0.6651 - val_accuracy: 0.7396\n",
            "Epoch 58/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8802 - val_loss: 0.6872 - val_accuracy: 0.7500\n",
            "Epoch 59/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2824 - accuracy: 0.8880 - val_loss: 0.7013 - val_accuracy: 0.7396\n",
            "Epoch 60/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8880 - val_loss: 0.6824 - val_accuracy: 0.7500\n",
            "Epoch 61/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8854 - val_loss: 0.6649 - val_accuracy: 0.7292\n",
            "Epoch 62/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8672 - val_loss: 0.6495 - val_accuracy: 0.7292\n",
            "Epoch 63/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8841 - val_loss: 0.6790 - val_accuracy: 0.7292\n",
            "Epoch 64/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8867 - val_loss: 0.6710 - val_accuracy: 0.7292\n",
            "Epoch 65/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2900 - accuracy: 0.8919 - val_loss: 0.6607 - val_accuracy: 0.7292\n",
            "Epoch 66/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8815 - val_loss: 0.6633 - val_accuracy: 0.7188\n",
            "Epoch 67/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2795 - accuracy: 0.8906 - val_loss: 0.6785 - val_accuracy: 0.7292\n",
            "Epoch 68/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3127 - accuracy: 0.8750 - val_loss: 0.6674 - val_accuracy: 0.7500\n",
            "Epoch 69/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.9036 - val_loss: 0.6705 - val_accuracy: 0.7500\n",
            "Epoch 70/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.8906 - val_loss: 0.6991 - val_accuracy: 0.7500\n",
            "Epoch 71/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8880 - val_loss: 0.7201 - val_accuracy: 0.7396\n",
            "Epoch 72/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2554 - accuracy: 0.8997 - val_loss: 0.7390 - val_accuracy: 0.7396\n",
            "Epoch 73/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2630 - accuracy: 0.8906 - val_loss: 0.6959 - val_accuracy: 0.7396\n",
            "Epoch 74/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8906 - val_loss: 0.7324 - val_accuracy: 0.7500\n",
            "Epoch 75/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.8815 - val_loss: 0.7047 - val_accuracy: 0.7500\n",
            "Epoch 76/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8776 - val_loss: 0.6840 - val_accuracy: 0.7396\n",
            "Epoch 77/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.8724 - val_loss: 0.6986 - val_accuracy: 0.7604\n",
            "Epoch 78/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.8841 - val_loss: 0.7316 - val_accuracy: 0.7292\n",
            "Epoch 79/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.9049 - val_loss: 0.7190 - val_accuracy: 0.7292\n",
            "Epoch 80/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.8906 - val_loss: 0.7084 - val_accuracy: 0.7396\n",
            "Epoch 81/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2945 - accuracy: 0.8685 - val_loss: 0.7212 - val_accuracy: 0.7500\n",
            "Epoch 82/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.8841 - val_loss: 0.7171 - val_accuracy: 0.7604\n",
            "Epoch 83/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9010 - val_loss: 0.7145 - val_accuracy: 0.7604\n",
            "Epoch 84/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8971 - val_loss: 0.6802 - val_accuracy: 0.7708\n",
            "Epoch 85/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8945 - val_loss: 0.6769 - val_accuracy: 0.7500\n",
            "Epoch 86/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.8945 - val_loss: 0.7084 - val_accuracy: 0.7604\n",
            "Epoch 87/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2579 - accuracy: 0.8984 - val_loss: 0.7224 - val_accuracy: 0.7604\n",
            "Epoch 88/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2826 - accuracy: 0.8802 - val_loss: 0.7337 - val_accuracy: 0.7708\n",
            "Epoch 89/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.9089 - val_loss: 0.7337 - val_accuracy: 0.7500\n",
            "Epoch 90/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8867 - val_loss: 0.7520 - val_accuracy: 0.7396\n",
            "Epoch 91/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8867 - val_loss: 0.7325 - val_accuracy: 0.7500\n",
            "Epoch 92/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2503 - accuracy: 0.8958 - val_loss: 0.7574 - val_accuracy: 0.7604\n",
            "Epoch 93/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8919 - val_loss: 0.7462 - val_accuracy: 0.7396\n",
            "Epoch 94/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2419 - accuracy: 0.8971 - val_loss: 0.7481 - val_accuracy: 0.7500\n",
            "Epoch 95/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2299 - accuracy: 0.9128 - val_loss: 0.7796 - val_accuracy: 0.7396\n",
            "Epoch 96/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8932 - val_loss: 0.7538 - val_accuracy: 0.7500\n",
            "Epoch 97/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2338 - accuracy: 0.8997 - val_loss: 0.7564 - val_accuracy: 0.7500\n",
            "Epoch 98/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8997 - val_loss: 0.7826 - val_accuracy: 0.7604\n",
            "Epoch 99/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.8893 - val_loss: 0.7675 - val_accuracy: 0.7396\n",
            "Epoch 100/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.8997 - val_loss: 0.7500 - val_accuracy: 0.7604\n",
            "Epoch 101/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8958 - val_loss: 0.7762 - val_accuracy: 0.7604\n",
            "Epoch 102/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.9023 - val_loss: 0.7715 - val_accuracy: 0.7292\n",
            "Epoch 103/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.8919 - val_loss: 0.7960 - val_accuracy: 0.7292\n",
            "Epoch 104/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2529 - accuracy: 0.8971 - val_loss: 0.7829 - val_accuracy: 0.7500\n",
            "Epoch 105/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9102 - val_loss: 0.7697 - val_accuracy: 0.7396\n",
            "Epoch 106/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2599 - accuracy: 0.8984 - val_loss: 0.7826 - val_accuracy: 0.7500\n",
            "Epoch 107/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2194 - accuracy: 0.9062 - val_loss: 0.8071 - val_accuracy: 0.7500\n",
            "Epoch 108/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9010 - val_loss: 0.8108 - val_accuracy: 0.7292\n",
            "Epoch 109/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9010 - val_loss: 0.8060 - val_accuracy: 0.7500\n",
            "Epoch 110/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2526 - accuracy: 0.8932 - val_loss: 0.8078 - val_accuracy: 0.7604\n",
            "Epoch 111/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2259 - accuracy: 0.9115 - val_loss: 0.8333 - val_accuracy: 0.7396\n",
            "Epoch 112/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.8971 - val_loss: 0.8518 - val_accuracy: 0.7292\n",
            "Epoch 113/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.9141 - val_loss: 0.8603 - val_accuracy: 0.7188\n",
            "Epoch 114/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9010 - val_loss: 0.8398 - val_accuracy: 0.7292\n",
            "Epoch 115/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2344 - accuracy: 0.8945 - val_loss: 0.8267 - val_accuracy: 0.7292\n",
            "Epoch 116/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.9128 - val_loss: 0.8130 - val_accuracy: 0.7292\n",
            "Epoch 117/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2343 - accuracy: 0.8984 - val_loss: 0.8354 - val_accuracy: 0.7500\n",
            "Epoch 118/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2408 - accuracy: 0.9128 - val_loss: 0.8549 - val_accuracy: 0.7292\n",
            "Epoch 119/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.9076 - val_loss: 0.8826 - val_accuracy: 0.7188\n",
            "Epoch 120/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2115 - accuracy: 0.9193 - val_loss: 0.8335 - val_accuracy: 0.7188\n",
            "Epoch 121/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2092 - accuracy: 0.9245 - val_loss: 0.8695 - val_accuracy: 0.7396\n",
            "Epoch 122/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2352 - accuracy: 0.9010 - val_loss: 0.8559 - val_accuracy: 0.7396\n",
            "Epoch 123/250\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.2208 - accuracy: 0.9089 - val_loss: 0.8303 - val_accuracy: 0.7292\n",
            "Epoch 124/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2477 - accuracy: 0.8906 - val_loss: 0.8255 - val_accuracy: 0.7188\n",
            "Epoch 125/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2447 - accuracy: 0.9010 - val_loss: 0.8377 - val_accuracy: 0.7396\n",
            "Epoch 126/250\n",
            "39/39 [==============================] - 0s 6ms/step - loss: 0.2274 - accuracy: 0.9062 - val_loss: 0.8487 - val_accuracy: 0.7083\n",
            "Epoch 127/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2798 - accuracy: 0.8880 - val_loss: 0.8039 - val_accuracy: 0.7188\n",
            "Epoch 128/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2401 - accuracy: 0.9089 - val_loss: 0.8035 - val_accuracy: 0.7396\n",
            "Epoch 129/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9036 - val_loss: 0.8415 - val_accuracy: 0.7292\n",
            "Epoch 130/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8971 - val_loss: 0.8334 - val_accuracy: 0.7083\n",
            "Epoch 131/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9062 - val_loss: 0.8696 - val_accuracy: 0.7604\n",
            "Epoch 132/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9258 - val_loss: 0.8339 - val_accuracy: 0.7396\n",
            "Epoch 133/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2215 - accuracy: 0.9206 - val_loss: 0.8558 - val_accuracy: 0.7396\n",
            "Epoch 134/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2218 - accuracy: 0.9115 - val_loss: 0.8566 - val_accuracy: 0.7396\n",
            "Epoch 135/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9180 - val_loss: 0.7922 - val_accuracy: 0.7604\n",
            "Epoch 136/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.8997 - val_loss: 0.8190 - val_accuracy: 0.7500\n",
            "Epoch 137/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2205 - accuracy: 0.9128 - val_loss: 0.8936 - val_accuracy: 0.7292\n",
            "Epoch 138/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9154 - val_loss: 0.8691 - val_accuracy: 0.7396\n",
            "Epoch 139/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9141 - val_loss: 0.8292 - val_accuracy: 0.7292\n",
            "Epoch 140/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2181 - accuracy: 0.9167 - val_loss: 0.8494 - val_accuracy: 0.7188\n",
            "Epoch 141/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2393 - accuracy: 0.8971 - val_loss: 0.8655 - val_accuracy: 0.6875\n",
            "Epoch 142/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2198 - accuracy: 0.9115 - val_loss: 0.8405 - val_accuracy: 0.6979\n",
            "Epoch 143/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2372 - accuracy: 0.8958 - val_loss: 0.8390 - val_accuracy: 0.7292\n",
            "Epoch 144/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2491 - accuracy: 0.8919 - val_loss: 0.8441 - val_accuracy: 0.7396\n",
            "Epoch 145/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.9049 - val_loss: 0.8551 - val_accuracy: 0.7396\n",
            "Epoch 146/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2184 - accuracy: 0.9141 - val_loss: 0.8587 - val_accuracy: 0.7292\n",
            "Epoch 147/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.9271 - val_loss: 0.8708 - val_accuracy: 0.7188\n",
            "Epoch 148/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2390 - accuracy: 0.8971 - val_loss: 0.8511 - val_accuracy: 0.6979\n",
            "Epoch 149/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9219 - val_loss: 0.8254 - val_accuracy: 0.7292\n",
            "Epoch 150/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9115 - val_loss: 0.8021 - val_accuracy: 0.7188\n",
            "Epoch 151/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2112 - accuracy: 0.9141 - val_loss: 0.8281 - val_accuracy: 0.7396\n",
            "Epoch 152/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1822 - accuracy: 0.9193 - val_loss: 0.8528 - val_accuracy: 0.7188\n",
            "Epoch 153/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9258 - val_loss: 0.8925 - val_accuracy: 0.7083\n",
            "Epoch 154/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9115 - val_loss: 0.8784 - val_accuracy: 0.7396\n",
            "Epoch 155/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9232 - val_loss: 0.8547 - val_accuracy: 0.7396\n",
            "Epoch 156/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2353 - accuracy: 0.9102 - val_loss: 0.8500 - val_accuracy: 0.7396\n",
            "Epoch 157/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2219 - accuracy: 0.9036 - val_loss: 0.8524 - val_accuracy: 0.7292\n",
            "Epoch 158/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.9036 - val_loss: 0.8799 - val_accuracy: 0.7396\n",
            "Epoch 159/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2403 - accuracy: 0.8997 - val_loss: 0.8616 - val_accuracy: 0.7396\n",
            "Epoch 160/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9167 - val_loss: 0.8108 - val_accuracy: 0.7396\n",
            "Epoch 161/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2037 - accuracy: 0.9141 - val_loss: 0.8422 - val_accuracy: 0.7396\n",
            "Epoch 162/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1895 - accuracy: 0.9310 - val_loss: 0.8946 - val_accuracy: 0.7188\n",
            "Epoch 163/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 0.9245 - val_loss: 0.9039 - val_accuracy: 0.7292\n",
            "Epoch 164/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2121 - accuracy: 0.9154 - val_loss: 0.9158 - val_accuracy: 0.7292\n",
            "Epoch 165/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9023 - val_loss: 0.8529 - val_accuracy: 0.7396\n",
            "Epoch 166/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2411 - accuracy: 0.8971 - val_loss: 0.8209 - val_accuracy: 0.7396\n",
            "Epoch 167/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9076 - val_loss: 0.8245 - val_accuracy: 0.7396\n",
            "Epoch 168/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2239 - accuracy: 0.9010 - val_loss: 0.8092 - val_accuracy: 0.7396\n",
            "Epoch 169/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2193 - accuracy: 0.9206 - val_loss: 0.8089 - val_accuracy: 0.7396\n",
            "Epoch 170/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2049 - accuracy: 0.9193 - val_loss: 0.8733 - val_accuracy: 0.7083\n",
            "Epoch 171/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9036 - val_loss: 0.8409 - val_accuracy: 0.7292\n",
            "Epoch 172/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1859 - accuracy: 0.9206 - val_loss: 0.8450 - val_accuracy: 0.7292\n",
            "Epoch 173/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9062 - val_loss: 0.8681 - val_accuracy: 0.7292\n",
            "Epoch 174/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.9128 - val_loss: 0.8315 - val_accuracy: 0.7500\n",
            "Epoch 175/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9180 - val_loss: 0.8589 - val_accuracy: 0.7083\n",
            "Epoch 176/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2294 - accuracy: 0.9089 - val_loss: 0.8334 - val_accuracy: 0.7188\n",
            "Epoch 177/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.8984 - val_loss: 0.8305 - val_accuracy: 0.7396\n",
            "Epoch 178/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9115 - val_loss: 0.8649 - val_accuracy: 0.7396\n",
            "Epoch 179/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9180 - val_loss: 0.8537 - val_accuracy: 0.7292\n",
            "Epoch 180/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1839 - accuracy: 0.9245 - val_loss: 0.8809 - val_accuracy: 0.7396\n",
            "Epoch 181/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9180 - val_loss: 0.9193 - val_accuracy: 0.7292\n",
            "Epoch 182/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.9128 - val_loss: 0.9325 - val_accuracy: 0.7292\n",
            "Epoch 183/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1944 - accuracy: 0.9219 - val_loss: 0.9239 - val_accuracy: 0.7292\n",
            "Epoch 184/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9310 - val_loss: 0.9141 - val_accuracy: 0.7292\n",
            "Epoch 185/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9115 - val_loss: 0.8881 - val_accuracy: 0.7500\n",
            "Epoch 186/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2108 - accuracy: 0.9180 - val_loss: 0.8632 - val_accuracy: 0.7396\n",
            "Epoch 187/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1827 - accuracy: 0.9232 - val_loss: 0.8746 - val_accuracy: 0.7188\n",
            "Epoch 188/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9297 - val_loss: 0.9238 - val_accuracy: 0.7292\n",
            "Epoch 189/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.9206 - val_loss: 0.9559 - val_accuracy: 0.7292\n",
            "Epoch 190/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.9102 - val_loss: 0.9510 - val_accuracy: 0.7396\n",
            "Epoch 191/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9245 - val_loss: 0.9720 - val_accuracy: 0.7292\n",
            "Epoch 192/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9232 - val_loss: 0.9695 - val_accuracy: 0.7188\n",
            "Epoch 193/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2150 - accuracy: 0.9141 - val_loss: 0.9479 - val_accuracy: 0.7188\n",
            "Epoch 194/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9206 - val_loss: 0.9280 - val_accuracy: 0.7396\n",
            "Epoch 195/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2121 - accuracy: 0.9036 - val_loss: 0.8993 - val_accuracy: 0.7292\n",
            "Epoch 196/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9349 - val_loss: 0.9329 - val_accuracy: 0.7500\n",
            "Epoch 197/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2000 - accuracy: 0.9193 - val_loss: 0.9474 - val_accuracy: 0.7292\n",
            "Epoch 198/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2052 - accuracy: 0.9232 - val_loss: 0.9431 - val_accuracy: 0.7083\n",
            "Epoch 199/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2105 - accuracy: 0.9089 - val_loss: 0.9261 - val_accuracy: 0.7188\n",
            "Epoch 200/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9284 - val_loss: 0.8879 - val_accuracy: 0.7396\n",
            "Epoch 201/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1883 - accuracy: 0.9245 - val_loss: 0.8866 - val_accuracy: 0.7396\n",
            "Epoch 202/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.9180 - val_loss: 0.8603 - val_accuracy: 0.7604\n",
            "Epoch 203/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9375 - val_loss: 0.8696 - val_accuracy: 0.7396\n",
            "Epoch 204/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9102 - val_loss: 0.8882 - val_accuracy: 0.7396\n",
            "Epoch 205/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1969 - accuracy: 0.9154 - val_loss: 0.9119 - val_accuracy: 0.7292\n",
            "Epoch 206/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2178 - accuracy: 0.9102 - val_loss: 0.8972 - val_accuracy: 0.7500\n",
            "Epoch 207/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9349 - val_loss: 0.8778 - val_accuracy: 0.7396\n",
            "Epoch 208/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2081 - accuracy: 0.9193 - val_loss: 0.8949 - val_accuracy: 0.7396\n",
            "Epoch 209/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9271 - val_loss: 0.8869 - val_accuracy: 0.7500\n",
            "Epoch 210/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9102 - val_loss: 0.9174 - val_accuracy: 0.7188\n",
            "Epoch 211/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9232 - val_loss: 0.8949 - val_accuracy: 0.7604\n",
            "Epoch 212/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9128 - val_loss: 0.8752 - val_accuracy: 0.7500\n",
            "Epoch 213/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9206 - val_loss: 0.8941 - val_accuracy: 0.7188\n",
            "Epoch 214/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9180 - val_loss: 0.8880 - val_accuracy: 0.7500\n",
            "Epoch 215/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1597 - accuracy: 0.9388 - val_loss: 0.8835 - val_accuracy: 0.7292\n",
            "Epoch 216/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9284 - val_loss: 0.9066 - val_accuracy: 0.7500\n",
            "Epoch 217/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1673 - accuracy: 0.9310 - val_loss: 0.9027 - val_accuracy: 0.7604\n",
            "Epoch 218/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9271 - val_loss: 0.9327 - val_accuracy: 0.7396\n",
            "Epoch 219/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9102 - val_loss: 0.9189 - val_accuracy: 0.7604\n",
            "Epoch 220/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1982 - accuracy: 0.9258 - val_loss: 0.9134 - val_accuracy: 0.7292\n",
            "Epoch 221/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9154 - val_loss: 0.9080 - val_accuracy: 0.7292\n",
            "Epoch 222/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9154 - val_loss: 0.9098 - val_accuracy: 0.7708\n",
            "Epoch 223/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9245 - val_loss: 0.9282 - val_accuracy: 0.7500\n",
            "Epoch 224/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1913 - accuracy: 0.9258 - val_loss: 0.9407 - val_accuracy: 0.7604\n",
            "Epoch 225/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1794 - accuracy: 0.9310 - val_loss: 0.9180 - val_accuracy: 0.7396\n",
            "Epoch 226/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1805 - accuracy: 0.9245 - val_loss: 0.8790 - val_accuracy: 0.7812\n",
            "Epoch 227/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9375 - val_loss: 0.8954 - val_accuracy: 0.7812\n",
            "Epoch 228/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1898 - accuracy: 0.9219 - val_loss: 0.9147 - val_accuracy: 0.7708\n",
            "Epoch 229/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9323 - val_loss: 0.9186 - val_accuracy: 0.7708\n",
            "Epoch 230/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1587 - accuracy: 0.9362 - val_loss: 0.9749 - val_accuracy: 0.7500\n",
            "Epoch 231/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1942 - accuracy: 0.9128 - val_loss: 0.9779 - val_accuracy: 0.7500\n",
            "Epoch 232/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9349 - val_loss: 0.9420 - val_accuracy: 0.7396\n",
            "Epoch 233/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2005 - accuracy: 0.9154 - val_loss: 0.9192 - val_accuracy: 0.7604\n",
            "Epoch 234/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9401 - val_loss: 0.8794 - val_accuracy: 0.7500\n",
            "Epoch 235/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1903 - accuracy: 0.9193 - val_loss: 0.8870 - val_accuracy: 0.7500\n",
            "Epoch 236/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.9141 - val_loss: 0.8931 - val_accuracy: 0.7500\n",
            "Epoch 237/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1740 - accuracy: 0.9258 - val_loss: 0.8837 - val_accuracy: 0.7604\n",
            "Epoch 238/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9310 - val_loss: 0.9069 - val_accuracy: 0.7500\n",
            "Epoch 239/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1599 - accuracy: 0.9323 - val_loss: 0.9107 - val_accuracy: 0.7396\n",
            "Epoch 240/250\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.9297 - val_loss: 0.9245 - val_accuracy: 0.7292\n",
            "Epoch 241/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1667 - accuracy: 0.9323 - val_loss: 0.9208 - val_accuracy: 0.7292\n",
            "Epoch 242/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.9427 - val_loss: 0.9260 - val_accuracy: 0.7396\n",
            "Epoch 243/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2093 - accuracy: 0.9115 - val_loss: 0.9287 - val_accuracy: 0.7292\n",
            "Epoch 244/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1688 - accuracy: 0.9362 - val_loss: 0.9409 - val_accuracy: 0.7292\n",
            "Epoch 245/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2003 - accuracy: 0.9219 - val_loss: 0.9088 - val_accuracy: 0.7396\n",
            "Epoch 246/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9388 - val_loss: 0.9060 - val_accuracy: 0.7396\n",
            "Epoch 247/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9167 - val_loss: 0.9160 - val_accuracy: 0.7500\n",
            "Epoch 248/250\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9375 - val_loss: 0.9142 - val_accuracy: 0.7500\n",
            "Epoch 249/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9336 - val_loss: 0.9448 - val_accuracy: 0.7396\n",
            "Epoch 250/250\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9323 - val_loss: 0.9528 - val_accuracy: 0.7604\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fecc85ae710>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_dev)\n",
        "y_pred_tres = pd.DataFrame(y_pred)[0].apply(lambda x:1 if x>0.5 else 0)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_dev, y_pred_tres)\n",
        "\n",
        "print(\"F1 score:\", f1)\n",
        "tn, fp, fn, tp = confusion_matrix(y_dev, y_pred_tres).ravel()\n",
        "print(tn, fp, fn, tp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE9jEKc0sc17",
        "outputId": "64d6a9ed-ee1d-4b29-be66-2c001c32a004"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step\n",
            "F1 score: 0.6101694915254238\n",
            "55 9 14 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "0Sr-MsKenBCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f45f9a-fb90-44c3-a9a6-298eb90715d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(384, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming you have trained and fitted a scikit-learn model named 'model'\n",
        "# Save the model to a file\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "id": "CcDAalFRaarw"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FZlJupUJrOl",
        "outputId": "676544c9-e364-4a96-93a3-78a2464059b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "7hDj1Qf4HUWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('model.h5')"
      ],
      "metadata": {
        "id": "P-oz2tlsKB1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqNLrW2pdGmL",
        "outputId": "c082f629-b245-4176-a799-294382289724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict([X_test])"
      ],
      "metadata": {
        "id": "xaY8AzXZdHKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961ce230-917f-4a6a-82ec-49d2b3259a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction[prediction>0.5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0St4pBGgdj-",
        "outputId": "65100b45-ce1d-42b3-b956-5f65502dd964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.93191504, 0.99849546, 0.99999934, 0.9999989 , 0.7655071 ,\n",
              "       0.99381405, 0.9848924 , 0.9999915 , 0.82392126, 0.99936   ,\n",
              "       0.99848783], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pd.DataFrame(y_pred)[0].apply(lambda x:1 if x>0.5 else 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zppLmVI9hHRg",
        "outputId": "4d61c4f4-c1a2-46c3-99fd-e49056e20b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     0\n",
            "1     0\n",
            "2     1\n",
            "3     1\n",
            "4     1\n",
            "5     0\n",
            "6     0\n",
            "7     0\n",
            "8     1\n",
            "9     0\n",
            "10    0\n",
            "11    0\n",
            "12    0\n",
            "13    0\n",
            "14    1\n",
            "15    0\n",
            "16    0\n",
            "17    0\n",
            "18    0\n",
            "19    0\n",
            "20    0\n",
            "21    0\n",
            "22    0\n",
            "23    0\n",
            "24    0\n",
            "25    0\n",
            "26    0\n",
            "27    1\n",
            "28    0\n",
            "29    0\n",
            "30    0\n",
            "31    0\n",
            "32    0\n",
            "33    1\n",
            "34    0\n",
            "35    0\n",
            "36    1\n",
            "37    0\n",
            "38    1\n",
            "39    0\n",
            "40    0\n",
            "41    0\n",
            "42    0\n",
            "43    1\n",
            "44    0\n",
            "45    0\n",
            "46    1\n",
            "47    0\n",
            "48    0\n",
            "49    0\n",
            "50    0\n",
            "51    0\n",
            "52    0\n",
            "53    0\n",
            "Name: 0, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBmDmQwmtDXE",
        "outputId": "5b3e88e9-52c4-407f-bfa3-7f682f646434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5c7YSHRvJKz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}